Lmod has detected the following error: The following module(s) are unknown: "anaconda/2023.03"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore_cache load "anaconda/2023.03"

Also make sure that all modulefiles written in TCL start with the string #%Module



/var/spool/slurm/job9940377/slurm_script: line 15: activate: No such file or directory
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /scratch/gilbreth/shar1159/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type      | Params | Mode  | In sizes | Out sizes
-------------------------------------------------------------------
0 | model | BaseModel | 332 K  | train | [1, 96]  | [1, 40]  
-------------------------------------------------------------------
332 K     Trainable params
0         Non-trainable params
332 K     Total params
1.331     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.
`Trainer.fit` stopped: `max_epochs=10` reached.
