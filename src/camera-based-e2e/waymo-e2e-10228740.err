Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /scratch/gilbreth/shar1159/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name  | Type     | Params | Mode  | FLOPs
---------------------------------------------------
0 | model | NewModel | 28.1 M | train | 0    
---------------------------------------------------
1.3 M     Trainable params
26.8 M    Non-trainable params
28.1 M    Total params
112.541   Total estimated model params size (MB)
244       Modules in train mode
0         Modules in eval mode
0         Total Flops
SLURM auto-requeueing enabled. Setting signal handlers.
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
`Trainer.fit` stopped: `max_epochs=10` reached.
Traceback (most recent call last):
  File "/scratch/gilbreth/shar1159/robotvision/src/camera-based-e2e/train.py", line 134, in <module>
    lit_model.export_scene_loss_json(test_loader)  # writes to scene_loss.json (or LitModel's configured path)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/robotvision/src/camera-based-e2e/models/shrey_model.py", line 73, in export_scene_loss_json
    pred = self(batch)  # (B, 20, 2)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/robotvision/src/camera-based-e2e/models/shrey_model.py", line 41, in forward
    return self.model(x)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/robotvision/src/camera-based-e2e/models/shrey_model.py", line 150, in forward
    cam_feats = self.features(larger_tensor)[0]
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 632, in _fn
    return fn(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/robotvision/src/camera-based-e2e/models/shrey_model.py", line 113, in forward
    feats = self.sam_model(x_t)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/timm/models/_features.py", line 476, in forward
    features = self.model.forward_intermediates(
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/timm/models/hieradet_sam2.py", line 501, in forward_intermediates
    x = self.patch_embed(x)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/timm/models/hieradet_sam2.py", line 265, in forward
    x = self.proj(x)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/scratch/gilbreth/shar1159/conda_envs/waymo/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Input type (c10::BFloat16) and bias type (float) should be the same
srun: error: gilbreth-h001: task 0: Exited with exit code 1
